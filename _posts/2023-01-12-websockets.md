---
layout: post
title: "WebSockets: a Comparison between Open-Source JVM Technologies"
author: matteo.ricci
categories: [ Software Development, Backend, Web Development, Websocket, Kotlin, Java, Spring-Boot, Ktor, JVM ]
image: assets/images/websockets/0.png
excerpt: "A Benchmark of some JVM WebSocket Servers"
---

## Introduction
In this work, I employed state-of-the-art, open-source, **JVM** technologies to assess the performances of a WebSocket server under progressive system overload. The focus of the study is comparing two non-blocking models: **Spring Webflux** and **Ktor**.
We will compare those systems also with a thread-per-request engine. I will leave room for a discussion about the Spring Boot WebSockets engine, highlighting the 
performance gap between these models.

<center>
    <img src="{{ site.url }}{{ site.baseurl }}/assets/images/websockets/1.png" width="400">
    <br>
    <em> A WebSocket server receives messages and notifies subscribers (Image generated by the author with <a href="https://openai.com/dall-e-2/">E-Dell</a>)</em>
</center>
<br>
WebSocket is a communication protocol that supplies two-way communication between client and server.
When a client opens a WebSockets, the server can push back messages at any time. 
That is in contrast with the **HTTP** client-server model, where a server cannot initiate a 
message transfer to a client but can only respond to an **HTTP** request from a client. 
By keeping the communication channel open, a WebSockets server allows the simultaneous sending and receiving 
of messages among the connected clients through the server itself. 

## Methods
Our primary goal is to think about a minimal system, making the side effects not relevant. Latency for example.
This can be done with an echo server, in which both the server and client run on a local machine.
This system forwards to the client the message the client has just sent. 
Such a simple toy model allows us to apply progressive system overload by increasing the number of concurrent users. 
I will perform two different runs for each tecnhology. Both of them are carried out with **Apache JMeter**. 

The first one (from now on **easy mode**) is structered in the following way: 
- consider an initial chunk of 50 users connected to the echo server. 
- keep increasing connections in chunks of 200 up to the **maximum overload state**, with 2000 concurrent users.
- keep the system in the maximum overload state for 3 minutes.
- start dropping out connections in chunks of 400 until the number of active connections drops to 0.
If any communication errors happen, the existing connection will be closed, kicking out the user from the echo server.

The second run (from now on **hard mode**) has the following structure:
- in a time range of 30 seconds, increase the number of active connections from 0 up to 12000
- keep the system in the maximum overload state for 1000 seconds.
- drop all the existing connections.

During the simulations, we care about:
- collect data describing the server response over time.
- the actual number of concurrent users over time (may be different from the planned one, since if a communication error happens the connection will be closed).
- the percentage of requests processed with an error outcome.
- the number of exchanged bytes between the clients and the echo server.
- the server throughput (number of requests processed per second).

Every simulation is performed using a **5 kb** text sample to exchange between the client and server. 

We will have **many clients** continuously exchanging messages with the server for both **easy** and **hard** modes. 
In these scenarios, if the delay between consecutive messages from the same user is too little, 
the server will be unable to deal with the overload. This should be avoided.
A good compromise is imposing every user has a *physiological* delay when exchaning consecutive messages.
This perfectly matches with a real-world-use case. 
For this reason, I modeled the delay between consecutive messages of a single user with a Gaussian distribution. 
This distribution has **mean value** of **5 sec.** and **standard deviation** of **2 sec.** 

<center>
    <img src="{{ site.url }}{{ site.baseurl }}/assets/images/websockets/3.png" width="400">
    <br>
    <br>
    <em> Gaussian distribution of the delay every user exchanges messages with. The image is generated by the author.</em>
</center>
<br>
Using this model, we ensure that *averagely* each user exchanges a message with the server every 5 seconds and 
the probability of waiting between 1 and 9 seconds before exchanging another message is almost maximized (**95%**).

The code snippets for **Ktor** and **Webflux** echo servers are listed below.

<p style="margin : 0; padding-bottom:0;"> <em> Ktor WebSocket server. Ktor version: 2.3.2 -see <a href="https://ktor.io/docs/websocket.html">here</a>).</em> </p>
```kotlin
fun Application.configureSockets() {
    install(WebSockets) {
        pingPeriod = Duration.ofSeconds(10)
        timeout = Duration.ofSeconds(15)
        maxFrameSize = Long.MAX_VALUE
        masking = false
    }
    routing {
        webSocket("/ktor") {
            for (frame in incoming) {
                frame as? Frame.Text ?: continue
                val userMessage = frame.readText()
                send(userMessage)
            }
        }
    }
}
```


<p style="margin : 0; padding-bottom:0;"> <em> WebFlux WebSocket server. Spring-Boot version: 2.6.7</em> </p>
```java
@Component
public class ReactiveServerWebSocketHandler implements WebSocketHandler {

    @Override
    public @NotNull
    Mono<Void> handle(@NotNull WebSocketSession session) {
        return session.send(session.receive()
                .map(WebSocketMessage::getPayloadAsText)
                .map(session::textMessage)
        );
    }
}
```

## Maximum overload of 2000 users (easy mode)
In this section I investigate how the systems responds when the maximum amount of concurrent users is reasonably small and the maximum overload state is reached progressively.
<center>
    <img src="{{ site.url }}{{ site.baseurl }}/assets/images/websockets/ktor_webflux_2000.png" width="1000">
    <br>
    <em> In the top panel the number of connected users during the run is presented. In the bottom panel, the comparison between the even-loop-based echo server performances is shown. The Image produced by the author using the software R. </em>
</center>
<br>
For both the technologies employed, none of the incoming requests have an error outcome. 
Also, the amount of exchanged Kb per second and the server throughputs are very similar: so far it seems that both technologies are pretty performant. 

However, let's try to deeper investigate the results.
The dotted lines represent the raw data of the server response over time. 
As we can see, randomly distributed higher peaks corresponding to fluctuations up to 20 ms are present. 
To understand the relative impact of those peaks with respect to the averagely observed values, 
I made an interpolation of the raw data using the software **R**. The results of this procedure are shown with solid lines. 
Looking at those lines, it is clear that, regardless of fluctuations, 
the average response time for **Ktor** lies slightly below 
the one observed for **WebFlux**. This clarifies what is going on with the overall simulation parameters reported in the table. 
Indeed, the interpolated trends reflect the slightly better simulation results of **Ktor**. 
Most importantly, it indicates the low impact of the observed fluctuations. So far, both the technologies ensure stability during the run. 

## Maximum overload of 12000 users (hard mode)
In this case, the goal is to study what happens when the time under maximum overload is longer and also the number of concurrent users is larger.

<center>
    <img src="{{ site.url }}{{ site.baseurl }}/assets/images/websockets/ktor_webflux_12000.png" width="1000">
    <br>
    <em> In the top panel the number of connected users during the run. In the bottom panel, the comparison between the even-loop-based echo server performances is shown. The Image produced by the author using the software R. </em>
</center>
<br>
First of all, the data in the table show that both the systems were able to correctly process all the incoming requests.
Also, the server throughputs  and the amount of exchanged Kb/sec are very similar. 
Anyway, in constrast to what experienced before, **the two systems bheave differently against this larger overload**. 
In this case Ktor shows larger fluctuations of the response time, while Webflux  is stable. 
This is confirmed by the interpolated trends. Those trends indicate that WebFlux takes averagely **6/7 ms** less than Ktor to respond to the client.
The shift between the two trends in this case is clearly due to the impact of the observed instabilities.  
Interestingly, this suggests the usage of the WebFlux non-blocking engine for systems in which a larger amount of concurrency is predicted.

Finally, it is worth to point out that the results presented rely on single runs. This means they lack statistical ensemble wideness. 
In other words, to give a better outcome about the best-performing, the number of simulations to carry out should be larger.


## A Didactical Digression
It is interesting to do the same experiment in the **easy mode** by adopting a thread-per-request model. 
We build the same kind of echo-server but this time I use the standard WebSocket engine provided by Spring Boot. 
<p style="margin : 0; padding-bottom:0;"> <em> Thread-per-request WebSocket server.</em> </p>
```java
@Component
public class ServerWebSocketHandler extends TextWebSocketHandler {

    @Override
    public void afterConnectionEstablished(WebSocketSession session) {
        session.setTextMessageSizeLimit(20000000);
    }

    @Override
    public void handleTextMessage(WebSocketSession callerSession, @NotNull TextMessage toForward) throws IOException {
        String content = toForward.getPayload();
        callerSession.sendMessage(new TextMessage(content));
    }
}
```
<center>
    <img src="{{ site.url }}{{ site.baseurl }}/assets/images/websockets/normal-results.png" width="1000">
    <br>
    <em> In the top panel the number of connected users during the run. In the bottom panel, the comparison between the even-loop-based echo server performances is shown. Image produced using raw data from JMeter. </em>
</center>
<br>
In this case, the echo server can't handle more than roughly 100 concurrent connections, as indicated by the overall results parameters of the run. 
In particular, an error percentage of around 12 % and a lower server throughput (15.4 /sec) are detected. 
Also, looking at the server response over time, we can see a response time peak at every instant a new connections chunk comes in. 
The interpretation we can give on those results is intuitive. 
The trends clearly indicate that the thread-per-request server is unable to process a large amount of requests.
Indeed, looking at the trends, we observe that the servers starts kicking out users. 
This happens every time the number of concurrent connections rise above around 100.

This indicates that the employed **thread-per-request** model can't handle a high number of concurrent requests: 
this model is not optimal when the number of concurrent clients is high. 
An explanation can be provided thinking about the fact that the **JVM** thread pool has a finite size. Let us call this size **S**. 
The thred-per-request model works in such a way a single thread will take care of the entire **life-cycle** of an incoming request. 
Let us say the duration of this lyfe-cycle is **T**. 
If the number of concurrent requests is greater than **S** and **T** is non-negligible, then the system will run out of resources.
This also explains why non-blocking models are preferred for those kind of applications.


In conclusion, I created an echo-server model to assess the performances of state-of-the-art event loop technologies, 
showcasing their high-level performances. 
On the other hand, I have created the same echo server employing a thread-per-request engine.
I compared the results of both non-blocking and thread-per-request strategy and I explicitely showed the non-blocking model outperforms the thread-per-request one.